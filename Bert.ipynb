{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.autonotebook import tqdm\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "train_df, val_df = model_selection.train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7aef27c516</td>\n",
       "      <td>Doctor Who has finished</td>\n",
       "      <td>Doctor Who has finished</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415660cb0e</td>\n",
       "      <td>you should.</td>\n",
       "      <td>you should.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fdc228bbe</td>\n",
       "      <td>back at school again. almost weekend. oh wait,...</td>\n",
       "      <td>back at school again. almost weekend. oh wait,...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ea91e5a7ab</td>\n",
       "      <td>My computer is SO slooowww this morning.  I th...</td>\n",
       "      <td>My computer is SO slooowww this morning.  I th...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f2022b87f</td>\n",
       "      <td>On my way to dazzle bar!!</td>\n",
       "      <td>On my way to dazzle bar!!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  7aef27c516                            Doctor Who has finished   \n",
       "1  415660cb0e                                        you should.   \n",
       "2  4fdc228bbe  back at school again. almost weekend. oh wait,...   \n",
       "3  ea91e5a7ab  My computer is SO slooowww this morning.  I th...   \n",
       "4  8f2022b87f                          On my way to dazzle bar!!   \n",
       "\n",
       "                                       selected_text sentiment  \n",
       "0                            Doctor Who has finished   neutral  \n",
       "1                                        you should.   neutral  \n",
       "2  back at school again. almost weekend. oh wait,...   neutral  \n",
       "3  My computer is SO slooowww this morning.  I th...   neutral  \n",
       "4                          On my way to dazzle bar!!   neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tokenizer.encode(train_df.text[3], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tokenizer.encode(train_df.selected_text[3], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my computer is so slooowww this morning. i think it ` s a sign that i should go home and play in my yard.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_encoder(x):\n",
    "    if x == 'negative': return 0\n",
    "    elif x == 'neutral': return 1\n",
    "    else: return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sentiment = train_df.sentiment.apply(sentiment_encoder)\n",
    "val_df.sentiment = val_df.sentiment.apply(sentiment_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    t, st = x\n",
    "    start_idx = t.index(st)\n",
    "    end_idx = start_idx + len(st) - 1\n",
    "    if st == 0: return st\n",
    "    while start_idx > 0 and t[start_idx-1] != ' ':\n",
    "        start_idx -= 1\n",
    "    return  t[start_idx:end_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is a test'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ('This is a test', 's a test')\n",
    "standardize(x) # Should return 'is a test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text = train_df.text.astype('str')\n",
    "train_df.selected_text = train_df.selected_text.astype('str')\n",
    "val_df.text = val_df.text.astype('str')\n",
    "val_df.selected_text = val_df.selected_text.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['both_text'] = list(zip(train_df.text, train_df.selected_text))\n",
    "val_df['both_text'] = list(zip(val_df.text, val_df.selected_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['selected_text2'] = train_df['both_text'].apply(standardize)\n",
    "val_df['selected_text2'] = val_df['both_text'].apply(standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affected val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5198"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_df.selected_text == val_df.selected_text2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5497, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tok_text'] = train_df.text.apply(lambda x: tokenizer.encode(x, add_special_tokens=False))\n",
    "val_df['tok_text'] = val_df.text.apply(lambda x: tokenizer.encode(x, add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tok_selected_text'] = train_df.selected_text2.apply(lambda x: tokenizer.encode(x, add_special_tokens=False))\n",
    "val_df['tok_selected_text'] = val_df.selected_text2.apply(lambda x: tokenizer.encode(x, add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in train_df.tok_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in train_df.tok_selected_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['both_text'] = list(zip(train_df.tok_text, train_df.tok_selected_text))\n",
    "val_df['both_text'] = list(zip(val_df.tok_text, val_df.tok_selected_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>both_text</th>\n",
       "      <th>selected_text2</th>\n",
       "      <th>tok_text</th>\n",
       "      <th>tok_selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7aef27c516</td>\n",
       "      <td>Doctor Who has finished</td>\n",
       "      <td>Doctor Who has finished</td>\n",
       "      <td>1</td>\n",
       "      <td>([3460, 2040, 2038, 2736], [3460, 2040, 2038, ...</td>\n",
       "      <td>Doctor Who has finished</td>\n",
       "      <td>[3460, 2040, 2038, 2736]</td>\n",
       "      <td>[3460, 2040, 2038, 2736]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415660cb0e</td>\n",
       "      <td>you should.</td>\n",
       "      <td>you should.</td>\n",
       "      <td>1</td>\n",
       "      <td>([2017, 2323, 1012], [2017, 2323, 1012])</td>\n",
       "      <td>you should.</td>\n",
       "      <td>[2017, 2323, 1012]</td>\n",
       "      <td>[2017, 2323, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4fdc228bbe</td>\n",
       "      <td>back at school again. almost weekend. oh wait,...</td>\n",
       "      <td>back at school again. almost weekend. oh wait,...</td>\n",
       "      <td>1</td>\n",
       "      <td>([2067, 2012, 2082, 2153, 1012, 2471, 5353, 10...</td>\n",
       "      <td>back at school again. almost weekend. oh wait,...</td>\n",
       "      <td>[2067, 2012, 2082, 2153, 1012, 2471, 5353, 101...</td>\n",
       "      <td>[2067, 2012, 2082, 2153, 1012, 2471, 5353, 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ea91e5a7ab</td>\n",
       "      <td>My computer is SO slooowww this morning.  I th...</td>\n",
       "      <td>My computer is SO slooowww this morning.  I th...</td>\n",
       "      <td>1</td>\n",
       "      <td>([2026, 3274, 2003, 2061, 22889, 9541, 5004, 2...</td>\n",
       "      <td>My computer is SO slooowww this morning.  I th...</td>\n",
       "      <td>[2026, 3274, 2003, 2061, 22889, 9541, 5004, 28...</td>\n",
       "      <td>[2026, 3274, 2003, 2061, 22889, 9541, 5004, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f2022b87f</td>\n",
       "      <td>On my way to dazzle bar!!</td>\n",
       "      <td>On my way to dazzle bar!!</td>\n",
       "      <td>1</td>\n",
       "      <td>([2006, 2026, 2126, 2000, 4830, 17644, 3347, 9...</td>\n",
       "      <td>On my way to dazzle bar!!</td>\n",
       "      <td>[2006, 2026, 2126, 2000, 4830, 17644, 3347, 99...</td>\n",
       "      <td>[2006, 2026, 2126, 2000, 4830, 17644, 3347, 99...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  7aef27c516                            Doctor Who has finished   \n",
       "1  415660cb0e                                        you should.   \n",
       "2  4fdc228bbe  back at school again. almost weekend. oh wait,...   \n",
       "3  ea91e5a7ab  My computer is SO slooowww this morning.  I th...   \n",
       "4  8f2022b87f                          On my way to dazzle bar!!   \n",
       "\n",
       "                                       selected_text  sentiment  \\\n",
       "0                            Doctor Who has finished          1   \n",
       "1                                        you should.          1   \n",
       "2  back at school again. almost weekend. oh wait,...          1   \n",
       "3  My computer is SO slooowww this morning.  I th...          1   \n",
       "4                          On my way to dazzle bar!!          1   \n",
       "\n",
       "                                           both_text  \\\n",
       "0  ([3460, 2040, 2038, 2736], [3460, 2040, 2038, ...   \n",
       "1           ([2017, 2323, 1012], [2017, 2323, 1012])   \n",
       "2  ([2067, 2012, 2082, 2153, 1012, 2471, 5353, 10...   \n",
       "3  ([2026, 3274, 2003, 2061, 22889, 9541, 5004, 2...   \n",
       "4  ([2006, 2026, 2126, 2000, 4830, 17644, 3347, 9...   \n",
       "\n",
       "                                      selected_text2  \\\n",
       "0                            Doctor Who has finished   \n",
       "1                                        you should.   \n",
       "2  back at school again. almost weekend. oh wait,...   \n",
       "3  My computer is SO slooowww this morning.  I th...   \n",
       "4                          On my way to dazzle bar!!   \n",
       "\n",
       "                                            tok_text  \\\n",
       "0                           [3460, 2040, 2038, 2736]   \n",
       "1                                 [2017, 2323, 1012]   \n",
       "2  [2067, 2012, 2082, 2153, 1012, 2471, 5353, 101...   \n",
       "3  [2026, 3274, 2003, 2061, 22889, 9541, 5004, 28...   \n",
       "4  [2006, 2026, 2126, 2000, 4830, 17644, 3347, 99...   \n",
       "\n",
       "                                   tok_selected_text  \n",
       "0                           [3460, 2040, 2038, 2736]  \n",
       "1                                 [2017, 2323, 1012]  \n",
       "2  [2067, 2012, 2082, 2153, 1012, 2471, 5353, 101...  \n",
       "3  [2026, 3274, 2003, 2061, 22889, 9541, 5004, 28...  \n",
       "4  [2006, 2026, 2126, 2000, 4830, 17644, 3347, 99...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get start and end index for tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(x):\n",
    "    t, st = x\n",
    "    for i, j in enumerate(t):\n",
    "        if t[i:i+len(st)] == st:\n",
    "            return i, i+len(st)\n",
    "    return -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes = train_df.both_text.apply(get_indexes)\n",
    "val_indexes = val_df.both_text.apply(get_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['start_idx'] = train_indexes.map(lambda x: x[0])\n",
    "train_df['end_idx'] = train_indexes.map(lambda x: x[1])\n",
    "val_df['start_idx'] = val_indexes.map(lambda x: x[0])\n",
    "val_df['end_idx'] = val_indexes.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For test set, if it's -1, will just predict the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[train_df.start_idx!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = val_df.loc[val_df.start_idx!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x):\n",
    "    return x + ([0] * (108-len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tok_text'] = train_df['tok_text'].apply(pad)\n",
    "val_df['tok_text'] = val_df['tok_text'].apply(pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweets(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self): return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        return {'text': row.text, 'selected_text': row.selected_text, 'tok_text': torch.Tensor(row.tok_text), \n",
    "                'tok_selected_text': torch.Tensor(row.tok_selected_text), \n",
    "                'start_idx': row.start_idx, 'end_idx': row.end_idx,\n",
    "                'sentiment': row.sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Tweets(train_df)\n",
    "val_ds = Tweets(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Doctor Who has finished',\n",
       " 'selected_text': 'Doctor Who has finished',\n",
       " 'tok_text': tensor([3460., 2040., 2038., 2736.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]),\n",
       " 'tok_selected_text': tensor([3460., 2040., 2038., 2736.]),\n",
       " 'start_idx': 0,\n",
       " 'end_idx': 4,\n",
       " 'sentiment': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_ds, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, sent_v=3, sent_emb=50, p=0.5):\n",
    "        super().__init__()\n",
    "        self.sent_emb = nn.Embedding(sent_v, sent_emb)\n",
    "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.start = nn.Linear(108*768+sent_emb, 1)\n",
    "        self.end = nn.Linear(108*768+sent_emb, 1)\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, sent):\n",
    "        sent = self.sent_emb(sent)\n",
    "        sent = self.drop(sent)\n",
    "        x = self.bert(x)[0]\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.drop(x)\n",
    "        x = torch.cat((x, sent), dim=1)\n",
    "        x = self.relu(x)\n",
    "        return self.start(x), self.end(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['http://tinyurl.com/oqsqz6 Grace`s FunZen magic mood tool for keeping her cool in the pool of real life which is now yours too'],\n",
       " 'selected_text': ['for keeping her cool in the pool'],\n",
       " 'tok_text': tensor([[ 8299.,  1024.,  1013.,  1013.,  4714.,  3126.,  2140.,  1012.,  4012.,\n",
       "           1013.,  1051.,  4160.,  2015.,  4160.,  2480.,  2575.,  4519.,  1036.,\n",
       "           1055.,  4569., 10431.,  3894.,  6888.,  6994.,  2005.,  4363.,  2014.,\n",
       "           4658.,  1999.,  1996.,  4770.,  1997.,  2613.,  2166.,  2029.,  2003.,\n",
       "           2085.,  6737.,  2205.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "              0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.]]),\n",
       " 'tok_selected_text': tensor([[2005., 4363., 2014., 4658., 1999., 1996., 4770.]]),\n",
       " 'start_idx': tensor([24]),\n",
       " 'end_idx': tensor([31]),\n",
       " 'sentiment': tensor([2])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5272]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.1233]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch['tok_text'].long(), batch['sentiment'].long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (sent_emb): Embedding(3, 50)\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (start): Linear(in_features=82994, out_features=1, bias=True)\n",
       "  (end): Linear(in_features=82994, out_features=1, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_ds, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizers, dl, loss_fn=nn.MSELoss()):\n",
    "    model.train()\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        x = batch['tok_text'].to(device)\n",
    "        sent = batch['sentiment'].to(device)\n",
    "        start_idx = batch['start_idx'].to(device)\n",
    "        end_idx = batch['end_idx'].to(device)\n",
    "        s, e = model(x.long(), sent.long())\n",
    "        loss = loss_fn(start_idx, s)\n",
    "        loss += loss_fn(end_idx, e)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()/len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, dl, loss_fn=nn.MSELoss()):\n",
    "    model.eval()\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        x = batch['tok_text'].to(device)\n",
    "        sent = batch['sentiment'].to(device)\n",
    "        start_idx = batch['start_idx'].to(device)\n",
    "        end_idx = batch['end_idx'].to(device)\n",
    "        s, e = model(x.long(), sent.long())\n",
    "        loss = loss_fn(start_idx, s)\n",
    "        loss += loss_fn(end_idx, e)\n",
    "    pred = batch['tok_selected_text'][0][int(s):int(e)]\n",
    "    pred = tokenizer.decode(pred)\n",
    "    print(f'Text: {batch[\"text\"]}, Selected: {batch[\"selected_text\"]}, Pred: {pred}')\n",
    "    return loss.item()/len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "#     print(param)\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (sent_emb): Embedding(3, 50)\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (start): Linear(in_features=82994, out_features=1, bias=True)\n",
       "  (end): Linear(in_features=82994, out_features=1, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.start.weight.requires_grad = True\n",
    "model.end.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21466 [00:00<?, ?it/s]/home/sthodla/anaconda3/envs/panda/lib/python3.7/site-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|| 21466/21466 [07:40<00:00, 46.66it/s]\n",
      "100%|| 5353/5353 [01:42<00:00, 52.22it/s]\n",
      "  0%|          | 0/21466 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['watching a movie and rocking my baby kitty who is asleep in my sling hanging from my neck. So cute'], Selected: ['watching a movie and rocking my baby kitty who is asleep in my sling hanging from my neck. So cute'], Pred: from my neck. so cute\n",
      "Epoch 1: Train Loss: 0.020673303471732914, Val Loss: 0.07333659074606237\n",
      "Save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21466/21466 [07:36<00:00, 47.04it/s]\n",
      "100%|| 5353/5353 [01:40<00:00, 53.09it/s]\n",
      "  0%|          | 0/21466 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['watching a movie and rocking my baby kitty who is asleep in my sling hanging from my neck. So cute'], Selected: ['watching a movie and rocking my baby kitty who is asleep in my sling hanging from my neck. So cute'], Pred: movie and rocking my\n",
      "Epoch 2: Train Loss: 0.00903468877063219, Val Loss: 0.04184654915686881\n",
      "Save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21466/21466 [07:38<00:00, 46.86it/s]\n",
      "100%|| 5353/5353 [01:41<00:00, 52.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['watching a movie and rocking my baby kitty who is asleep in my sling hanging from my neck. So cute'], Selected: ['watching a movie and rocking my baby kitty who is asleep in my sling hanging from my neck. So cute'], Pred: from my neck. so\n",
      "Epoch 3: Train Loss: 0.022647665385085718, Val Loss: 0.04322066967139484\n",
      "Save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "for i in range(1, 4):\n",
    "    tl = train(model, optimizer, train_dl)\n",
    "    vl = val(model, val_dl)\n",
    "    print(f'Epoch {i}: Train Loss: {tl}, Val Loss: {vl}')\n",
    "    if vl < best_loss:\n",
    "        print('Save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'local_models/bert_v1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = Tweets(val_df)\n",
    "val_dl = DataLoader(val_ds, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERT()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('local_models/bert_v1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_pred(model, dl, loss_fn=nn.MSELoss()):\n",
    "    model.eval()\n",
    "    output = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        x = batch['tok_text'].to(device)\n",
    "        sent = batch['sentiment'].to(device)\n",
    "        s, e = model(x.long(), sent.long())\n",
    "        pred = batch['tok_text'][0][int(s):int(e)]\n",
    "        pred = [i for i in pred if i != 0]\n",
    "        pred = tokenizer.decode(pred)\n",
    "        output.append(pred)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5353/5353 [02:18<00:00, 38.78it/s]\n"
     ]
    }
   ],
   "source": [
    "output = val_pred(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>both_text</th>\n",
       "      <th>selected_text2</th>\n",
       "      <th>tok_text</th>\n",
       "      <th>tok_selected_text</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7f72a928a</td>\n",
       "      <td>WOOOOOOOOOO   are you coming to Nottingham at...</td>\n",
       "      <td>t?  lovelovelove</td>\n",
       "      <td>2</td>\n",
       "      <td>([15854, 9541, 9541, 9541, 9541, 2024, 2017, 2...</td>\n",
       "      <td>point?  lovelovelove</td>\n",
       "      <td>[15854, 9541, 9541, 9541, 9541, 2024, 2017, 27...</td>\n",
       "      <td>[2391, 1029, 2293, 14301, 18349, 3726]</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ef42dee96c</td>\n",
       "      <td>resting had a whole day of walking</td>\n",
       "      <td>resting had a whole day of walking</td>\n",
       "      <td>1</td>\n",
       "      <td>([8345, 2018, 1037, 2878, 2154, 1997, 3788], [...</td>\n",
       "      <td>resting had a whole day of walking</td>\n",
       "      <td>[8345, 2018, 1037, 2878, 2154, 1997, 3788, 0, ...</td>\n",
       "      <td>[8345, 2018, 1037, 2878, 2154, 1997, 3788]</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07d17131b1</td>\n",
       "      <td>was in Palawan a couple of days ago, i`ll try ...</td>\n",
       "      <td>was in Palawan a couple of days ago, i`ll try ...</td>\n",
       "      <td>1</td>\n",
       "      <td>([2001, 1999, 14412, 25903, 1037, 3232, 1997, ...</td>\n",
       "      <td>was in Palawan a couple of days ago, i`ll try ...</td>\n",
       "      <td>[2001, 1999, 14412, 25903, 1037, 3232, 1997, 2...</td>\n",
       "      <td>[2001, 1999, 14412, 25903, 1037, 3232, 1997, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2820205db5</td>\n",
       "      <td>I know! I`m so slow its horrible. DON`T TELL ...</td>\n",
       "      <td>horrible.</td>\n",
       "      <td>0</td>\n",
       "      <td>([1045, 2113, 999, 1045, 1036, 1049, 2061, 403...</td>\n",
       "      <td>horrible.</td>\n",
       "      <td>[1045, 2113, 999, 1045, 1036, 1049, 2061, 4030...</td>\n",
       "      <td>[9202, 1012]</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7d3ce4363c</td>\n",
       "      <td>Glad I went out, glad I didn`t leave early, an...</td>\n",
       "      <td>glad</td>\n",
       "      <td>2</td>\n",
       "      <td>([5580, 1045, 2253, 2041, 1010, 5580, 1045, 21...</td>\n",
       "      <td>glad</td>\n",
       "      <td>[5580, 1045, 2253, 2041, 1010, 5580, 1045, 213...</td>\n",
       "      <td>[5580]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  a7f72a928a   WOOOOOOOOOO   are you coming to Nottingham at...   \n",
       "1  ef42dee96c                 resting had a whole day of walking   \n",
       "2  07d17131b1  was in Palawan a couple of days ago, i`ll try ...   \n",
       "3  2820205db5   I know! I`m so slow its horrible. DON`T TELL ...   \n",
       "4  7d3ce4363c  Glad I went out, glad I didn`t leave early, an...   \n",
       "\n",
       "                                       selected_text  sentiment  \\\n",
       "0                                   t?  lovelovelove          2   \n",
       "1                 resting had a whole day of walking          1   \n",
       "2  was in Palawan a couple of days ago, i`ll try ...          1   \n",
       "3                                          horrible.          0   \n",
       "4                                               glad          2   \n",
       "\n",
       "                                           both_text  \\\n",
       "0  ([15854, 9541, 9541, 9541, 9541, 2024, 2017, 2...   \n",
       "1  ([8345, 2018, 1037, 2878, 2154, 1997, 3788], [...   \n",
       "2  ([2001, 1999, 14412, 25903, 1037, 3232, 1997, ...   \n",
       "3  ([1045, 2113, 999, 1045, 1036, 1049, 2061, 403...   \n",
       "4  ([5580, 1045, 2253, 2041, 1010, 5580, 1045, 21...   \n",
       "\n",
       "                                      selected_text2  \\\n",
       "0                               point?  lovelovelove   \n",
       "1                 resting had a whole day of walking   \n",
       "2  was in Palawan a couple of days ago, i`ll try ...   \n",
       "3                                          horrible.   \n",
       "4                                               glad   \n",
       "\n",
       "                                            tok_text  \\\n",
       "0  [15854, 9541, 9541, 9541, 9541, 2024, 2017, 27...   \n",
       "1  [8345, 2018, 1037, 2878, 2154, 1997, 3788, 0, ...   \n",
       "2  [2001, 1999, 14412, 25903, 1037, 3232, 1997, 2...   \n",
       "3  [1045, 2113, 999, 1045, 1036, 1049, 2061, 4030...   \n",
       "4  [5580, 1045, 2253, 2041, 1010, 5580, 1045, 213...   \n",
       "\n",
       "                                   tok_selected_text  start_idx  end_idx  \n",
       "0             [2391, 1029, 2293, 14301, 18349, 3726]         12       18  \n",
       "1         [8345, 2018, 1037, 2878, 2154, 1997, 3788]          0        7  \n",
       "2  [2001, 1999, 14412, 25903, 1037, 3232, 1997, 2...          0       19  \n",
       "3                                       [9202, 1012]          9       11  \n",
       "4                                             [5580]          0        1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['pred_sel_text'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['both_pred'] = list(zip(val_df.pred_sel_text, val_df.selected_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(s1, s2):\n",
    "    a = set(s1.lower().split()) \n",
    "    b = set(s2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['jaccard'] = val_df.both_pred.apply(lambda x: jaccard(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2379280405649789"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.jaccard.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
