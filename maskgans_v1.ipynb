{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:15:53.065019Z",
     "start_time": "2020-06-12T03:15:48.661701Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chainer\n",
    "\n",
    "### pytorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:47.662374Z",
     "start_time": "2020-06-12T03:33:47.641798Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB Data\n",
    "#### Question 1: Should the text be broken down to samples split on \"eos\" token?\n",
    "YES\n",
    "#### Question 2: Should the text be prepended with a sos token?\n",
    "YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:48.217901Z",
     "start_time": "2020-06-12T03:33:48.182184Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the data from chainer\n",
    "train, val, test = chainer.datasets.get_ptb_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:48.273247Z",
     "start_time": "2020-06-12T03:33:48.263935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: <class 'numpy.ndarray'> (929589,) [ 0  1  2 ... 39 26 24]\n",
      "val data: <class 'numpy.ndarray'> (73760,) [2211  396 1129 ...  108   27   24]\n",
      "test data: <class 'numpy.ndarray'> (82430,) [142  78  54 ...  87 214  24]\n"
     ]
    }
   ],
   "source": [
    "# the data is already separated into a numpy array\n",
    "print(f\"train data: {type(train)} {train.shape} {train}\")\n",
    "print(f\"val data: {type(val)} {val.shape} {val}\")\n",
    "print(f\"test data: {type(test)} {test.shape} {test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:48.630210Z",
     "start_time": "2020-06-12T03:33:48.618293Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabulary: 10003\n"
     ]
    }
   ],
   "source": [
    "# ptb_dict is a dictionary containing words (key) to idx (value)\n",
    "vocab2idx = chainer.datasets.get_ptb_words_vocabulary()\n",
    "vocab2idx = {k:v for k, v in vocab2idx.items()}\n",
    "\n",
    "#NOTE: PAD = 10000, <sos> = 10001, <m> = 10002\n",
    "vocab2idx['PAD'] = len(vocab2idx)\n",
    "vocab2idx['<sos>'] = 10001\n",
    "vocab2idx['<m>'] = 10002\n",
    "\n",
    "#creating a reverse dict to turn an index back into word for sanity check\n",
    "idx2vocab = {v:k for k, v in vocab2idx.items()}\n",
    "print(f\"Number of vocabulary: {len(vocab2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:49.106631Z",
     "start_time": "2020-06-12T03:33:49.097925Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_sentence(data):\n",
    "    \"\"\"\n",
    "    This function splits the text data into individual sentences split on the <eos> token\n",
    "    and prepends the <sos> token in the front.\n",
    "    \"\"\"\n",
    "    samples, sentence, eos_idx = [], [vocab2idx['<sos>']], vocab2idx['<eos>']\n",
    "    for idx in data:\n",
    "        if idx != eos_idx:  #25 is the idx for the <eos> token\n",
    "            sentence.append(idx)\n",
    "        else:\n",
    "            sentence.append(idx)\n",
    "            samples.append(sentence)\n",
    "            sentence = [vocab2idx['<sos>']]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:51.241071Z",
     "start_time": "2020-06-12T03:33:49.195962Z"
    }
   },
   "outputs": [],
   "source": [
    "#splitting each sequence as an individual sample\n",
    "train_samples = split_sentence(train)\n",
    "val_samples = split_sentence(val)\n",
    "test_samples = split_sentence(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:51.245581Z",
     "start_time": "2020-06-12T03:33:51.242505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> the asbestos fiber <unk> is unusually <unk> once it enters the <unk> with even brief exposures to it causing symptoms that show up decades later researchers said <eos>\n"
     ]
    }
   ],
   "source": [
    "sentence = [idx2vocab[idx] for idx in train_samples[5]]\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:51.345280Z",
     "start_time": "2020-06-12T03:33:51.246918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> eventually viewers may grow <unk> with the technology and <unk> the cost <eos>\n"
     ]
    }
   ],
   "source": [
    "#val_samples sequence\n",
    "sentence = [idx2vocab[idx] for idx in val_samples[5]]\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:51.428770Z",
     "start_time": "2020-06-12T03:33:51.346616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> heavy selling of standard & poor 's 500-stock index futures in chicago <unk> beat stocks downward <eos>\n"
     ]
    }
   ],
   "source": [
    "#test_samples sequence\n",
    "sentence = [idx2vocab[idx] for idx in test_samples[5]]\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:53.028844Z",
     "start_time": "2020-06-12T03:33:53.019082Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask_tokens(sentence, mask_prob, sub_prob):\n",
    "    mask_sent, count = [], int(len(sentence)*sub_prob)\n",
    "    for idx, token in enumerate(sentence):\n",
    "        if np.random.uniform() < mask_prob and token not in [vocab2idx['<sos>'], vocab2idx['<eos>']]:\n",
    "            mask_sent.append(vocab2idx['<m>'])\n",
    "            count -= 1\n",
    "        else:\n",
    "            mask_sent.append(token)\n",
    "        if count == 0:\n",
    "            return mask_sent + sentence[idx+1:]\n",
    "    return mask_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:53.973321Z",
     "start_time": "2020-06-12T03:33:53.958826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that the masking worked\n",
    "len(mask_tokens(train_samples[0], .2, .2)), len(train_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:54.937043Z",
     "start_time": "2020-06-12T03:33:54.927847Z"
    }
   },
   "outputs": [],
   "source": [
    "class PTBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Setting up the Penn Tree Bank Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, mask_prob, sub_prob):\n",
    "        self.X = X\n",
    "        self.masked_X = [mask_tokens(x, mask_prob, sub_prob) for x in X]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.X[idx]), torch.LongTensor(self.masked_X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:59.262175Z",
     "start_time": "2020-06-12T03:33:56.781766Z"
    }
   },
   "outputs": [],
   "source": [
    "# calling on the dataset\n",
    "train_ds = PTBDataset(train_samples, .2, .2)\n",
    "val_ds = PTBDataset(val_samples, .2, .2)\n",
    "test_ds = PTBDataset(test_samples, .2, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:59.267589Z",
     "start_time": "2020-06-12T03:33:59.263903Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    \"\"\"\n",
    "    NOTE: batch without any labels is just a list of tensors coming from Dataset.\n",
    "    padding each sequence.\n",
    "    \"\"\"\n",
    "    (X, mask_X) = zip(*batch)\n",
    "    x_len = [len(x) for x in mask_X]\n",
    "    mask_x_pad = pad_sequence(mask_X, batch_first=True, padding_value=10000)\n",
    "    x_pad = pad_sequence(X, batch_first=True, padding_value=10000)\n",
    "    return mask_x_pad, x_pad, x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:33:59.353335Z",
     "start_time": "2020-06-12T03:33:59.268939Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "valid_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "#### Figure out how does bidirectional go with all of this? #### How to pass in bidirectional encoder vectors into a unidirectional decoder?\n",
    "* The encoder will generate hidden states that are of size 2*hidden_dimension (Encoder) size. I have to concatenate the two vectors of the hidden state. The cell state isnt really needed per Yannet but could still be used. The decoder hidden dimension size needs to be the same as the encoder. The concatenation should be done in the Seq2Seq.\n",
    "   \n",
    "#### Figure out how to do the masking for each sentence. How many tokens do we mask? Do they have to be in sequential order?\n",
    "* This was done setting a prob p of masking each token. The max number of tokens to mask is also set of a proportion length of the text. As a result, they were not done in sequential order.\n",
    "#### How to setup the Seq2Seq to generate text?\n",
    "* Perhaps it may be easier to go with Yannet's setup than benvrett? Need to discuss with Shirkar.\n",
    "\n",
    "#### Getting this error\n",
    "* AttributeError: 'int' object has no attribute 'backward'. The weird thing is that it trains for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:34:00.818294Z",
     "start_time": "2020-06-12T03:34:00.808065Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(.5)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = self.dropout(self.emb(x))\n",
    "        x_pack = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, (hidden, cell) = self.lstm(x_pack)  #NOTE: If (h_0, c_0) is not provided, both h_0 and c_0 default to zero.\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:34:01.411043Z",
     "start_time": "2020-06-12T03:34:01.401639Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenDecoder(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.dropout(self.emb(x))\n",
    "        out, (hidden, cell) = self.lstm(x, (h0, c0))  #passing in the initial hidden state and cell state\n",
    "        return self.linear(hidden[-1]), hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:34:02.842091Z",
     "start_time": "2020-06-12T03:34:02.807329Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_x, x, lengths = next(iter(train_dl))\n",
    "# mask_x, x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:34:06.115426Z",
     "start_time": "2020-06-12T03:34:06.098324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 64, 10]), torch.Size([2, 64, 10]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = GenEncoder(5, 10, len(vocab2idx))\n",
    "contexts, cells = encoder(mask_x, lengths)\n",
    "contexts.size(), cells.size()  # the context and cell tensors are shape: (n_layers*n_dir, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:34:09.369169Z",
     "start_time": "2020-06-12T03:34:09.360408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 20]), torch.Size([64, 20]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_contexts, flatten_cells = torch.flatten(contexts.transpose(1,0), 1), torch.flatten(cells.transpose(1,0), 1)\n",
    "flatten_contexts.size(), flatten_cells.size()  # after concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:34:10.768591Z",
     "start_time": "2020-06-12T03:34:10.762448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 20])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_contexts.unsqueeze(0).size()  #unsqueeze(0) to make shape: (n_layers*n_dir, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:36:00.906793Z",
     "start_time": "2020-06-12T03:36:00.899671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   32, 10002,   119,  5728,    42,  6351,   811,  2059,  1972,  1401,\n",
       "           32,  7360,  1107,    98,  8283,   383,    26,    27,  2968, 10002,\n",
       "         1457,  8854,  2281,  1094,  4417,    32,   169,    98,  1042, 10002,\n",
       "           26,    54,   131,    32,  2312,    35,  7965,    40,  8815,  1802,\n",
       "           42,    26,  2264,   159,   744,    40,  1333,   247,  1420,  9765,\n",
       "          296,    93,  3699,   687, 10002,   718,  1321,    27, 10002,   144,\n",
       "          125,  2011,   124,  7163])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_x[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:34:13.786705Z",
     "start_time": "2020-06-12T03:34:13.768636Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = GenDecoder(20, 20, len(vocab2idx))\n",
    "out, hidden, cell = decoder(x, flatten_contexts.unsqueeze(0), flatten_cells.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:18:22.620197Z",
     "start_time": "2020-06-12T00:18:22.616360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 77])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T23:57:25.064313Z",
     "start_time": "2020-06-11T23:57:25.056333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 20]), torch.Size([1, 64, 20]), torch.Size([64, 10003]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size(), cell.size(), out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:18:34.308445Z",
     "start_time": "2020-06-12T00:18:34.304023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10003])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:36:27.843393Z",
     "start_time": "2020-06-12T03:36:27.835930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 494, 7085, 2859, 4812, 9081, 2953, 4312, 9570, 4215, 1740, 8942, 2859,\n",
       "        4215, 2859, 4812, 2859, 2859, 8260, 5443, 5443, 5443, 4812, 5443, 4802,\n",
       "        3427, 6872,  494, 6872, 6872, 9081, 5443, 5443, 2859, 9081, 5005, 2611,\n",
       "        5702, 8920, 4215, 1740, 4812, 7085, 7733, 3674, 4659, 4659, 5443, 2859,\n",
       "        7699, 3427, 2859,  494, 6248,  494, 2859, 3427, 5702,  494, 1740, 6872,\n",
       "        9081, 3228, 7085, 2859], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:22:08.565369Z",
     "start_time": "2020-06-12T00:22:08.557926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_x[:, 6].unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:24:35.231764Z",
     "start_time": "2020-06-12T00:24:35.225837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:10:01.121807Z",
     "start_time": "2020-06-12T00:10:01.114243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:37:36.246853Z",
     "start_time": "2020-06-12T03:37:36.232001Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch(encoder, decoder, enc_optimizer, dec_optimizer, mask_x, x, lengths, train=True):\n",
    "    if train:\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "    # zero grad for both optimizers\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    # **ENCODER**\n",
    "    #passing the masked tokens into the encoder to retrieve context vectors and final cells\n",
    "    contexts, cells = encoder(mask_x, lengths)  # context, cell shape: (n_layers*n_dir, batch_size, hidden_dim)\n",
    "    \n",
    "    #first concatenate the bidirectional hidden & cell states into one context & cell tensors\n",
    "    #unsqueeze(0) to shape: (n_layers*n_dir, batch_size, hidden_dim)\n",
    "    hidden = torch.flatten(contexts.transpose(1,0), 1).unsqueeze(0)\n",
    "    cell = torch.flatten(cells.transpose(1,0), 1).unsqueeze(0) \n",
    "    \n",
    "    # **DECODER**\n",
    "    batch_size = mask_x.size(0)  #batch_size\n",
    "    batch_target_length = mask_x.size(1)  # this target length is the max seq length of batch_size\n",
    "    decoder_input  = mask_x[:, 0].unsqueeze(1)  #unsqueeze to make sure its still batch_size, idx_dim\n",
    "    \n",
    "    for idx in range(1, batch_target_length):\n",
    "        output, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "        x_idx = x[:,idx]   # dont think .unsqueeze(1) is necessary\n",
    "        \n",
    "        #if (x_idx.eq(10000)).sum() > 0:  <- discuss with shrikar whether this is necessary\n",
    "            # ignore the padding index so it doesnt count towards the loss\n",
    "        loss += F.cross_entropy(output, x_idx, ignore_index = 10000)\n",
    "        \n",
    "        # setting up for the next input USE torch.where!!!!\n",
    "        decoder_input = torch.where(mask_x[:,idx].eq(10002), output.argmax(dim=1), x[:,idx]).unsqueeze(1)\n",
    "        \n",
    "    # updating the gradient\n",
    "    if train:\n",
    "        loss.backward()  #one loss for both optimizers?\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:37:36.837471Z",
     "start_time": "2020-06-12T03:37:36.827492Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, val_dl, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        total, total_loss = 0, 0\n",
    "        total_v = 0\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        val_loss = 0\n",
    "        for mask_x, x, lengths in train_dl:\n",
    "            loss = batch(encoder, decoder, enc_optimizer, dec_optimizer, mask_x.to(device), x.to(device), lengths)\n",
    "            total_loss += loss*mask_x.size(0)\n",
    "            total += mask_x.size(0)\n",
    "        for mask_x, x, lengths in val_dl:\n",
    "            v_loss = batch(encoder, decoder, enc_optimizer, dec_optimizer, mask_x.to(device), x.to(device), lengths, False)\n",
    "            val_loss += v_loss*mask_x.size(0)\n",
    "            total_v += mask_x.size(0)\n",
    "        print(f\"Epoch {epoch+1}  Training Loss: {total_loss/total:.3f} Val Loss: {val_loss/total_v:.3f} Time: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:37:44.149276Z",
     "start_time": "2020-06-12T03:37:40.962822Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = GenEncoder(5, 10, len(vocab2idx)).to(device)\n",
    "decoder = GenDecoder(20, 20, len(vocab2idx)).to(device)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=.001)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:37:44.910474Z",
     "start_time": "2020-06-12T03:37:44.898162Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = PTBDataset(train_samples, .2, .2)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "val_ds = PTBDataset(val_samples, .2, .2)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T03:37:56.064841Z",
     "start_time": "2020-06-12T03:37:53.281427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  Training Loss: 476.187 Val Loss: 376.954 Time: 23.552446365356445\n",
      "Epoch 2  Training Loss: 377.950 Val Loss: 368.877 Time: 22.762675523757935\n",
      "Epoch 3  Training Loss: 374.850 Val Loss: 368.036 Time: 21.881603956222534\n",
      "Epoch 4  Training Loss: 371.566 Val Loss: 366.539 Time: 24.28552222251892\n",
      "Epoch 5  Training Loss: 374.652 Val Loss: 363.456 Time: 24.688134908676147\n",
      "Epoch 6  Training Loss: 369.885 Val Loss: 360.547 Time: 24.511171579360962\n",
      "Epoch 7  Training Loss: 364.771 Val Loss: 357.915 Time: 24.20044207572937\n",
      "Epoch 8  Training Loss: 365.724 Val Loss: 355.696 Time: 24.626968145370483\n",
      "Epoch 9  Training Loss: 362.720 Val Loss: 353.842 Time: 24.9388325214386\n",
      "Epoch 10  Training Loss: 359.964 Val Loss: 351.956 Time: 24.538982391357422\n"
     ]
    }
   ],
   "source": [
    "train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, val_dl, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
