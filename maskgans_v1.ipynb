{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:22.866933Z",
     "start_time": "2020-06-13T00:05:22.861526Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:24.476114Z",
     "start_time": "2020-06-13T00:05:23.251065Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chainer\n",
    "\n",
    "### pytorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:24.496578Z",
     "start_time": "2020-06-13T00:05:24.477774Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:25.701077Z",
     "start_time": "2020-06-13T00:05:24.670253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB Data\n",
    "#### Question 1: Should the text be broken down to samples split on \"eos\" token?\n",
    "YES\n",
    "#### Question 2: Should the text be prepended with a sos token?\n",
    "YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:26.781671Z",
     "start_time": "2020-06-13T00:05:26.746187Z"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking the data from chainer\n",
    "train, val, test = chainer.datasets.get_ptb_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:27.248937Z",
     "start_time": "2020-06-13T00:05:27.241390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: <class 'numpy.ndarray'> (929589,) [ 0  1  2 ... 39 26 24]\n",
      "val data: <class 'numpy.ndarray'> (73760,) [2211  396 1129 ...  108   27   24]\n",
      "test data: <class 'numpy.ndarray'> (82430,) [142  78  54 ...  87 214  24]\n"
     ]
    }
   ],
   "source": [
    "# the data is already separated into a numpy array\n",
    "print(f\"train data: {type(train)} {train.shape} {train}\")\n",
    "print(f\"val data: {type(val)} {val.shape} {val}\")\n",
    "print(f\"test data: {type(test)} {test.shape} {test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:27.882863Z",
     "start_time": "2020-06-13T00:05:27.868047Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabulary: 10003\n"
     ]
    }
   ],
   "source": [
    "# ptb_dict is a dictionary containing words (key) to idx (value)\n",
    "vocab2idx = chainer.datasets.get_ptb_words_vocabulary()\n",
    "vocab2idx = {k:v for k, v in vocab2idx.items()}\n",
    "\n",
    "#NOTE: PAD = 10000, <sos> = 10001, <m> = 10002\n",
    "vocab2idx['PAD'] = len(vocab2idx)\n",
    "vocab2idx['<sos>'] = 10001\n",
    "vocab2idx['<m>'] = 10002\n",
    "\n",
    "#creating a reverse dict to turn an index back into word for sanity check\n",
    "idx2vocab = {v:k for k, v in vocab2idx.items()}\n",
    "print(f\"Number of vocabulary: {len(vocab2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:28.430040Z",
     "start_time": "2020-06-13T00:05:28.421156Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_sentence(data):\n",
    "    \"\"\"\n",
    "    This function splits the text data into individual sentences split on the <eos> token\n",
    "    and prepends the <sos> token in the front.\n",
    "    \"\"\"\n",
    "    samples, sentence, eos_idx = [], [vocab2idx['<sos>']], vocab2idx['<eos>']\n",
    "    for idx in data:\n",
    "        if idx != eos_idx:  #25 is the idx for the <eos> token\n",
    "            sentence.append(idx)\n",
    "        else:\n",
    "            sentence.append(idx)\n",
    "            samples.append(sentence)\n",
    "            sentence = [vocab2idx['<sos>']]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:30.578545Z",
     "start_time": "2020-06-13T00:05:28.896764Z"
    }
   },
   "outputs": [],
   "source": [
    "#splitting each sequence as an individual sample\n",
    "train_samples = split_sentence(train)\n",
    "val_samples = split_sentence(val)\n",
    "test_samples = split_sentence(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:30.583493Z",
     "start_time": "2020-06-13T00:05:30.580102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> the asbestos fiber <unk> is unusually <unk> once it enters the <unk> with even brief exposures to it causing symptoms that show up decades later researchers said <eos>\n"
     ]
    }
   ],
   "source": [
    "sentence = [idx2vocab[idx] for idx in train_samples[5]]\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:30.673177Z",
     "start_time": "2020-06-13T00:05:30.584851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> eventually viewers may grow <unk> with the technology and <unk> the cost <eos>\n"
     ]
    }
   ],
   "source": [
    "#val_samples sequence\n",
    "sentence = [idx2vocab[idx] for idx in val_samples[5]]\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:30.749204Z",
     "start_time": "2020-06-13T00:05:30.674969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> heavy selling of standard & poor 's 500-stock index futures in chicago <unk> beat stocks downward <eos>\n"
     ]
    }
   ],
   "source": [
    "#test_samples sequence\n",
    "sentence = [idx2vocab[idx] for idx in test_samples[5]]\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:30.832438Z",
     "start_time": "2020-06-13T00:05:30.824389Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask_tokens(sentence, mask_prob, sub_prob):\n",
    "    mask_sent, count = [], int(len(sentence)*sub_prob)\n",
    "    for idx, token in enumerate(sentence):\n",
    "        if np.random.uniform() < mask_prob and token not in [vocab2idx['<sos>'], vocab2idx['<eos>']]:\n",
    "            mask_sent.append(vocab2idx['<m>'])\n",
    "            count -= 1\n",
    "        else:\n",
    "            mask_sent.append(token)\n",
    "        if count == 0:\n",
    "            return mask_sent + sentence[idx+1:]\n",
    "    return mask_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:31.658284Z",
     "start_time": "2020-06-13T00:05:31.651416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check that the masking worked\n",
    "len(mask_tokens(train_samples[0], .2, .2)), len(train_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:32.010282Z",
     "start_time": "2020-06-13T00:05:32.001041Z"
    }
   },
   "outputs": [],
   "source": [
    "class PTBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Setting up the Penn Tree Bank Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, mask_prob, sub_prob):\n",
    "        self.X = X\n",
    "        self.masked_X = [mask_tokens(x, mask_prob, sub_prob) for x in X]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.X[idx]), torch.LongTensor(self.masked_X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:35.103805Z",
     "start_time": "2020-06-13T00:05:32.549055Z"
    }
   },
   "outputs": [],
   "source": [
    "# calling on the dataset\n",
    "train_ds = PTBDataset(train_samples, .2, .2)\n",
    "val_ds = PTBDataset(val_samples, .2, .2)\n",
    "test_ds = PTBDataset(test_samples, .2, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:35.110661Z",
     "start_time": "2020-06-13T00:05:35.105272Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    \"\"\"\n",
    "    NOTE: batch without any labels is just a list of tensors coming from Dataset.\n",
    "    padding each sequence.\n",
    "    \"\"\"\n",
    "    (X, mask_X) = zip(*batch)\n",
    "    x_len = [len(x) for x in mask_X]\n",
    "    mask_x_pad = pad_sequence(mask_X, batch_first=True, padding_value=10000)\n",
    "    x_pad = pad_sequence(X, batch_first=True, padding_value=10000)\n",
    "    return mask_x_pad, x_pad, x_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "#### Figure out how does bidirectional go with all of this? #### How to pass in bidirectional encoder vectors into a unidirectional decoder?\n",
    "* The encoder will generate hidden states that are of size 2*hidden_dimension (Encoder) size. I have to concatenate the two vectors of the hidden state. The cell state isnt really needed per Yannet but could still be used. The decoder hidden dimension size needs to be the same as the encoder. The concatenation should be done in the Seq2Seq.\n",
    "   \n",
    "#### Figure out how to do the masking for each sentence. How many tokens do we mask? Do they have to be in sequential order?\n",
    "* This was done setting a prob p of masking each token. The max number of tokens to mask is also set of a proportion length of the text. As a result, they were not done in sequential order.\n",
    "#### How to setup the Seq2Seq to generate text?\n",
    "* Perhaps it may be easier to go with Yannet's setup than benvrett? Need to discuss with Shirkar.\n",
    "\n",
    "#### Getting this error\n",
    "* AttributeError: 'int' object has no attribute 'backward'. The weird thing is that it trains for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:38.555020Z",
     "start_time": "2020-06-13T00:05:38.543943Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(.5)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = self.dropout(self.emb(x))\n",
    "        x_pack = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, (hidden, cell) = self.lstm(x_pack)  #NOTE: If (h_0, c_0) is not provided, both h_0 and c_0 default to zero.\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:05:39.985872Z",
     "start_time": "2020-06-13T00:05:39.974383Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenDecoder(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, h0, c0):\n",
    "        x = self.dropout(self.emb(x))\n",
    "        out, (hidden, cell) = self.lstm(x, (h0, c0))  #passing in the initial hidden state and cell state\n",
    "        return self.linear(hidden[-1]), hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:06:37.582049Z",
     "start_time": "2020-06-13T00:06:37.549106Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "mask_x, x, lengths = next(iter(train_dl))\n",
    "# mask_x, x, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:06:40.720701Z",
     "start_time": "2020-06-13T00:06:40.654852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 10]), torch.Size([2, 3, 10]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = GenEncoder(5, 10, len(vocab2idx))\n",
    "contexts, cells = encoder(mask_x, lengths)\n",
    "contexts.size(), cells.size()  # the context and cell tensors are shape: (n_layers*n_dir, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:06:41.230610Z",
     "start_time": "2020-06-13T00:06:41.220476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 20]), torch.Size([3, 20]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_contexts, flatten_cells = torch.flatten(contexts.transpose(1,0), 1), torch.flatten(cells.transpose(1,0), 1)\n",
    "flatten_contexts.size(), flatten_cells.size()  # after concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T00:08:24.497857Z",
     "start_time": "2020-06-13T00:08:24.451464Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = GenDecoder(20, 20, len(vocab2idx))\n",
    "#unsqueeze(0) to make shape: (n_layers*n_dir, batch_size, hidden_dim)\n",
    "out, hidden, cell = decoder(x, flatten_contexts.unsqueeze(0), flatten_cells.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:12:15.018882Z",
     "start_time": "2020-06-12T16:12:15.003705Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch(encoder, decoder, enc_optimizer, dec_optimizer, mask_x, x, lengths, train=True):\n",
    "    if train:\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "    # zero grad for both optimizers\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    # **ENCODER**\n",
    "    #passing the masked tokens into the encoder to retrieve context vectors and final cells\n",
    "    contexts, cells = encoder(mask_x, lengths)  # context, cell shape: (n_layers*n_dir, batch_size, hidden_dim)\n",
    "    \n",
    "    #first concatenate the bidirectional hidden & cell states into one context & cell tensors\n",
    "    #unsqueeze(0) to shape: (n_layers*n_dir, batch_size, hidden_dim)\n",
    "    hidden = torch.flatten(contexts.transpose(1,0), 1).unsqueeze(0)\n",
    "    cell = torch.flatten(cells.transpose(1,0), 1).unsqueeze(0) \n",
    "    \n",
    "    # **DECODER**\n",
    "    batch_size = mask_x.size(0)  #batch_size\n",
    "    batch_target_length = mask_x.size(1)  # this target length is the max seq length of batch_size\n",
    "    decoder_input  = mask_x[:, 0].unsqueeze(1)  #unsqueeze to make sure its still batch_size, idx_dim\n",
    "    \n",
    "    for idx in range(1, batch_target_length):\n",
    "        output, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "        x_idx = x[:,idx]   # dont think .unsqueeze(1) is necessary\n",
    "        \n",
    "        #if (x_idx.eq(10000)).sum() > 0:  <- discuss with shrikar whether this is necessary\n",
    "        # ignore the padding index so it doesnt count towards the loss\n",
    "        loss += F.cross_entropy(output, x_idx, ignore_index = 10000)\n",
    "        \n",
    "        # setting up for the next input USE torch.where!!!!\n",
    "        decoder_input = torch.where(mask_x[:,idx].eq(10002), output.argmax(dim=1), x[:,idx]).unsqueeze(1)\n",
    "        \n",
    "    # updating the gradient\n",
    "    if train:\n",
    "        loss.backward()  #one loss for both optimizers?\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:12:22.788237Z",
     "start_time": "2020-06-12T16:12:22.775159Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, val_dl, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        total, total_loss = 0, 0\n",
    "        total_v = 0\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        val_loss = 0\n",
    "        for mask_x, x, lengths in train_dl:\n",
    "            loss = batch(encoder, decoder, enc_optimizer, dec_optimizer, mask_x.to(device), x.to(device), lengths)\n",
    "            total_loss += loss*mask_x.size(0)\n",
    "            total += mask_x.size(0)\n",
    "        for mask_x, x, lengths in val_dl:\n",
    "            v_loss = batch(encoder, decoder, enc_optimizer, dec_optimizer, mask_x.to(device), x.to(device), lengths, False)\n",
    "            val_loss += v_loss*mask_x.size(0)\n",
    "            total_v += mask_x.size(0)\n",
    "        print(f\"Epoch {epoch+1}  Training Loss: {total_loss/total:.3f} Val Loss: {val_loss/total_v:.3f} Time: {time.time()-start:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:14:44.410984Z",
     "start_time": "2020-06-12T16:14:38.553956Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = GenEncoder(32, 64, len(vocab2idx)).to(device)\n",
    "decoder = GenDecoder(128, 128, len(vocab2idx)).to(device)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=3e-4)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:15:11.460206Z",
     "start_time": "2020-06-12T16:15:09.128071Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = PTBDataset(train_samples, .2, .2)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "val_ds = PTBDataset(val_samples, .2, .2)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T16:18:52.970050Z",
     "start_time": "2020-06-12T16:15:13.809014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  Training Loss: 465.348 Val Loss: 367.445 Time: 22.478\n",
      "Epoch 2  Training Loss: 368.996 Val Loss: 359.982 Time: 21.576\n",
      "Epoch 3  Training Loss: 366.848 Val Loss: 352.303 Time: 21.960\n",
      "Epoch 4  Training Loss: 359.195 Val Loss: 347.145 Time: 21.867\n",
      "Epoch 5  Training Loss: 351.423 Val Loss: 343.290 Time: 21.786\n",
      "Epoch 6  Training Loss: 349.426 Val Loss: 339.886 Time: 21.827\n",
      "Epoch 7  Training Loss: 345.624 Val Loss: 337.359 Time: 21.937\n",
      "Epoch 8  Training Loss: 346.331 Val Loss: 335.091 Time: 22.017\n",
      "Epoch 9  Training Loss: 342.321 Val Loss: 332.801 Time: 21.914\n",
      "Epoch 10  Training Loss: 337.794 Val Loss: 330.642 Time: 21.795\n"
     ]
    }
   ],
   "source": [
    "# enc_dim (32, 64) dec_dim (128, 128)\n",
    "train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, val_dl, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T17:15:48.125540Z",
     "start_time": "2020-06-12T16:52:57.395003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  Training Loss: 422.180 Val Loss: 362.060 Time: 27.409\n",
      "Epoch 2  Training Loss: 365.786 Val Loss: 350.452 Time: 27.456\n",
      "Epoch 3  Training Loss: 355.386 Val Loss: 343.195 Time: 27.535\n",
      "Epoch 4  Training Loss: 350.261 Val Loss: 339.206 Time: 27.637\n",
      "Epoch 5  Training Loss: 343.994 Val Loss: 334.989 Time: 27.447\n",
      "Epoch 6  Training Loss: 339.982 Val Loss: 331.438 Time: 27.545\n",
      "Epoch 7  Training Loss: 335.620 Val Loss: 328.770 Time: 27.457\n",
      "Epoch 8  Training Loss: 332.161 Val Loss: 325.541 Time: 27.622\n",
      "Epoch 9  Training Loss: 329.105 Val Loss: 323.082 Time: 27.601\n",
      "Epoch 10  Training Loss: 324.382 Val Loss: 320.997 Time: 27.472\n",
      "Epoch 11  Training Loss: 320.734 Val Loss: 319.923 Time: 27.484\n",
      "Epoch 12  Training Loss: 318.205 Val Loss: 316.890 Time: 27.500\n",
      "Epoch 13  Training Loss: 315.016 Val Loss: 315.244 Time: 27.480\n",
      "Epoch 14  Training Loss: 311.844 Val Loss: 313.329 Time: 27.481\n",
      "Epoch 15  Training Loss: 308.919 Val Loss: 312.056 Time: 27.411\n",
      "Epoch 16  Training Loss: 306.655 Val Loss: 310.175 Time: 27.479\n",
      "Epoch 17  Training Loss: 306.454 Val Loss: 309.916 Time: 27.712\n",
      "Epoch 18  Training Loss: 302.542 Val Loss: 308.326 Time: 27.441\n",
      "Epoch 19  Training Loss: 300.730 Val Loss: 307.113 Time: 27.552\n",
      "Epoch 20  Training Loss: 297.469 Val Loss: 306.212 Time: 27.387\n",
      "Epoch 21  Training Loss: 294.531 Val Loss: 305.451 Time: 27.301\n",
      "Epoch 22  Training Loss: 292.082 Val Loss: 303.868 Time: 27.233\n",
      "Epoch 23  Training Loss: 290.813 Val Loss: 304.094 Time: 27.353\n",
      "Epoch 24  Training Loss: 290.827 Val Loss: 302.935 Time: 27.542\n",
      "Epoch 25  Training Loss: 287.031 Val Loss: 301.585 Time: 27.431\n",
      "Epoch 26  Training Loss: 282.800 Val Loss: 300.809 Time: 27.212\n",
      "Epoch 27  Training Loss: 282.985 Val Loss: 299.914 Time: 27.383\n",
      "Epoch 28  Training Loss: 282.218 Val Loss: 300.201 Time: 27.539\n",
      "Epoch 29  Training Loss: 277.689 Val Loss: 298.844 Time: 27.422\n",
      "Epoch 30  Training Loss: 277.517 Val Loss: 298.200 Time: 27.411\n",
      "Epoch 31  Training Loss: 273.196 Val Loss: 297.826 Time: 27.265\n",
      "Epoch 32  Training Loss: 273.790 Val Loss: 297.736 Time: 27.439\n",
      "Epoch 33  Training Loss: 270.829 Val Loss: 297.016 Time: 27.298\n",
      "Epoch 34  Training Loss: 268.351 Val Loss: 295.036 Time: 27.280\n",
      "Epoch 35  Training Loss: 265.510 Val Loss: 295.827 Time: 27.141\n",
      "Epoch 36  Training Loss: 264.497 Val Loss: 294.817 Time: 27.208\n",
      "Epoch 37  Training Loss: 262.614 Val Loss: 294.770 Time: 27.217\n",
      "Epoch 38  Training Loss: 261.504 Val Loss: 294.556 Time: 27.324\n",
      "Epoch 39  Training Loss: 259.638 Val Loss: 295.218 Time: 27.274\n",
      "Epoch 40  Training Loss: 260.296 Val Loss: 293.808 Time: 27.463\n",
      "Epoch 41  Training Loss: 259.226 Val Loss: 293.542 Time: 27.493\n",
      "Epoch 42  Training Loss: 255.544 Val Loss: 293.849 Time: 27.407\n",
      "Epoch 43  Training Loss: 255.467 Val Loss: 293.067 Time: 27.592\n",
      "Epoch 44  Training Loss: 252.274 Val Loss: 293.450 Time: 27.305\n",
      "Epoch 45  Training Loss: 251.376 Val Loss: 293.495 Time: 27.381\n",
      "Epoch 46  Training Loss: 248.746 Val Loss: 291.726 Time: 27.290\n",
      "Epoch 47  Training Loss: 248.410 Val Loss: 291.946 Time: 27.331\n",
      "Epoch 48  Training Loss: 247.247 Val Loss: 291.185 Time: 27.352\n",
      "Epoch 49  Training Loss: 245.442 Val Loss: 291.471 Time: 27.335\n",
      "Epoch 50  Training Loss: 243.721 Val Loss: 289.514 Time: 27.342\n"
     ]
    }
   ],
   "source": [
    "# enc_dim (64, 128) dec_dim (128, 256)\n",
    "encoder = GenEncoder(64, 128, len(vocab2idx)).to(device)\n",
    "decoder = GenDecoder(128, 256, len(vocab2idx)).to(device)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=3e-4)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=3e-4)\n",
    "train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, val_dl, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
