{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:16:55.770027Z",
     "start_time": "2020-06-16T03:16:55.765016Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:16:56.398350Z",
     "start_time": "2020-06-16T03:16:56.068272Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:16:57.436451Z",
     "start_time": "2020-06-16T03:16:56.462164Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "\n",
    "### Torch Packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:16:58.753800Z",
     "start_time": "2020-06-16T03:16:57.561897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:16:58.943505Z",
     "start_time": "2020-06-16T03:16:58.755408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:16:59.887117Z",
     "start_time": "2020-06-16T03:16:59.871547Z"
    }
   },
   "outputs": [],
   "source": [
    "# index 314 has no text\n",
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "* Lowercase - possible since the predicted sentiment text and the selected_text will be lowercase when computing metric.\n",
    "* punctuation - keep the punctuation given that the submission file states that need to be quoted and complete. \n",
    "* Numericalize - Turn each token into its corresponding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:02.123425Z",
     "start_time": "2020-06-16T03:17:02.117580Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    \"\"\"\n",
    "    This function will preprocess the input sentence sequence to avoid any further preprocessing\n",
    "    downstream.\n",
    "    \"\"\"\n",
    "    return sentence.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:02.756109Z",
     "start_time": "2020-06-16T03:17:02.475835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3cb7899bf1424fbafb8825644cd5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1f4b8f56ce41a085933e2f4673be76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949a0dddece5483fada7c82c3aaba67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3534.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lowercasing all the text and turning them into a list of tokens for text and selected text in the training set\n",
    "df_train['text'] = df_train['text'].progress_apply(preprocessing)\n",
    "df_train['selected_text'] = df_train['selected_text'].progress_apply(preprocessing)\n",
    "df_test['text'] = df_test['text'].progress_apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:05.264047Z",
     "start_time": "2020-06-16T03:17:05.244895Z"
    }
   },
   "outputs": [],
   "source": [
    "# making the sentiment to a variable\n",
    "df_train['sentiment'] = df_train['sentiment'].astype('category')\n",
    "df_train['code'] = df_train['sentiment'].cat.codes\n",
    "df_test['sentiment'] = df_test['sentiment'].astype('category')\n",
    "df_test['code'] = df_test['sentiment'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:06.769241Z",
     "start_time": "2020-06-16T03:17:06.751071Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>[i`d, have, responded,, if, i, were, going]</td>\n",
       "      <td>[i`d, have, responded,, if, i, were, going]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>[my, boss, is, bullying, me...]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>[what, interview!, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>[sons, of, ****,, why, couldn`t, they, put, th...</td>\n",
       "      <td>[sons, of, ****,]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1        [i`d, have, responded,, if, i, were, going]   \n",
       "1  549e992a42  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2  088c60f138                    [my, boss, is, bullying, me...]   \n",
       "3  9642c003ef               [what, interview!, leave, me, alone]   \n",
       "4  358bd9e861  [sons, of, ****,, why, couldn`t, they, put, th...   \n",
       "\n",
       "                                 selected_text sentiment  code  \n",
       "0  [i`d, have, responded,, if, i, were, going]   neutral     1  \n",
       "1                                  [sooo, sad]  negative     0  \n",
       "2                               [bullying, me]  negative     0  \n",
       "3                           [leave, me, alone]  negative     0  \n",
       "4                            [sons, of, ****,]  negative     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:09.093842Z",
     "start_time": "2020-06-16T03:17:09.087943Z"
    }
   },
   "outputs": [],
   "source": [
    "def unique_words(data):\n",
    "    \"\"\"\n",
    "    Find the number of unique words in the training set.\n",
    "    \"\"\"\n",
    "    words = set()\n",
    "    for text in data:\n",
    "        for word in text:\n",
    "            words.add(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:09.493727Z",
     "start_time": "2020-06-16T03:17:09.433328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45433"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unq_words = unique_words(df_train.text)\n",
    "len(unq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:11.213284Z",
     "start_time": "2020-06-16T03:17:11.201670Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(words):\n",
    "    vocab2idx, idx = {}, 5\n",
    "    vocab2idx['<pad>'] = 0\n",
    "    vocab2idx['<unk>'] = 1\n",
    "    vocab2idx['<sos>'] = 3\n",
    "    vocab2idx['<eos>'] = 4\n",
    "    \n",
    "    for word in words:\n",
    "        vocab2idx[word] = idx\n",
    "        idx += 1\n",
    "    return vocab2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:12.604727Z",
     "start_time": "2020-06-16T03:17:12.581789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45437"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2idx = create_vocabulary(unq_words)\n",
    "len(vocab2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:14.473606Z",
     "start_time": "2020-06-16T03:17:14.466971Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoding_with_no_padding(sentence, vocab2idx):\n",
    "    numericalize = [vocab2idx['<sos>']]\n",
    "    for token in sentence:\n",
    "        numericalize.append(vocab2idx.get(token, vocab2idx['<unk>']))\n",
    "    numericalize.append(vocab2idx['<eos>'])\n",
    "    return numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:16.264859Z",
     "start_time": "2020-06-16T03:17:16.254269Z"
    }
   },
   "outputs": [],
   "source": [
    "class tweetDataset(Dataset):\n",
    "    def __init__(self, data, vocab2idx):\n",
    "        self.X = [encoding_with_no_padding(x, vocab2idx) for x in data['text']]\n",
    "        self.y = [encoding_with_no_padding(y, vocab2idx) for y in data['selected_text']]\n",
    "        self.sentiment = data.code.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.X[idx]), torch.LongTensor(self.y[idx]), self.sentiment[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:18.352150Z",
     "start_time": "2020-06-16T03:17:18.166919Z"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "train_ds = tweetDataset(df_train, vocab2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:18.630880Z",
     "start_time": "2020-06-16T03:17:18.623739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3,  2283, 34539, 18750, 18013,  3699, 41583,  7089, 16660, 12664,\n",
       "        24897,  5416,  1355,     4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, s = train_ds[5]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:19.659746Z",
     "start_time": "2020-06-16T03:17:19.653637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:21.089825Z",
     "start_time": "2020-06-16T03:17:21.081846Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    (X, y, s) = zip(*batch)\n",
    "    x_len = [len(x) for x in X]\n",
    "    x_pad = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "    y_pad = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "    return x_pad, x_len, y_pad, torch.LongTensor(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:23.146962Z",
     "start_time": "2020-06-16T03:17:23.136674Z"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "batch_size = 3\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "x, lengths, y, s = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:36.185691Z",
     "start_time": "2020-06-16T03:17:36.173219Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, sentiment):\n",
    "        super().__init__()\n",
    "        self.vocabs = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.sentiment = nn.Embedding(sentiment, hidden_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(.5)\n",
    "        \n",
    "    def forward(self, x, lengths, sentiment):\n",
    "        x = self.dropout(self.vocabs(x))\n",
    "        x_pack = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, (hidden, cell) = self.lstm(x)\n",
    "        return hidden[-1] + self.sentiment(sentiment), cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:17:36.593704Z",
     "start_time": "2020-06-16T03:17:36.583100Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.vocabs = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = self.vocabs(x)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        return self.linear(hidden[-1]), hidden, cell  #NOTE: hidden[-1] returns everything within that batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:18:33.207002Z",
     "start_time": "2020-06-16T03:18:33.197013Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = Encoder(len(vocab2idx), 4, 8 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:19:24.321170Z",
     "start_time": "2020-06-16T03:19:24.308969Z"
    }
   },
   "outputs": [],
   "source": [
    "h, c = enc(x, lengths, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:19:36.579301Z",
     "start_time": "2020-06-16T03:19:36.572811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 8]), torch.Size([1, 3, 8]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size(), c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:22:24.076613Z",
     "start_time": "2020-06-16T03:22:24.072234Z"
    }
   },
   "outputs": [],
   "source": [
    "h = h.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:25:18.958164Z",
     "start_time": "2020-06-16T03:25:18.950594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [3],\n",
       "        [3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:26:28.989761Z",
     "start_time": "2020-06-16T03:26:28.975894Z"
    }
   },
   "outputs": [],
   "source": [
    "dec = Decoder(len(vocab2idx), 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:28:54.051877Z",
     "start_time": "2020-06-16T03:28:54.044696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0].unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:33:30.778818Z",
     "start_time": "2020-06-16T03:33:30.772172Z"
    }
   },
   "outputs": [],
   "source": [
    "out, hid, cell = dec(x[:, 0].unsqueeze(1), h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:37:24.572233Z",
     "start_time": "2020-06-16T03:37:24.565572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 29])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:48:36.304030Z",
     "start_time": "2020-06-16T03:48:36.293530Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, epochs=10):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        start = time.time()\n",
    "        total_loss, total = 0, 0\n",
    "        for x, lengths, y, s in train_dl:\n",
    "            loss = train_batch(encoder, decoder, enc_optimizer, dec_optimizer, x.to(device), y.to(device), s.to(device), lengths)\n",
    "            total_loss += loss*x.size(0)\n",
    "            total += x.size(0)\n",
    "        print(f\"Epoch: {epoch+1} Training Loss: {loss/total_loss:.3f} Time: {time.time()-start:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:49:07.760650Z",
     "start_time": "2020-06-16T03:49:07.746486Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(encoder, decoder, enc_optimizer, dec_optimizer, x, y, s, lengths,\n",
    "                teacher_forcing_ratio=0.5):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    # **ENCODER**\n",
    "    hidden, cell = encoder(x, lengths, s)  # passing both the sequence and the sentiment\n",
    "    hidden = hidden.unsqueeze(0)\n",
    "    \n",
    "    # **DECODER**\n",
    "    batch_target_length = y.size(1)  # NOTE: the length of the selected text\n",
    "    decoder_input = x[:, 0].unsqueeze(1)\n",
    "    \n",
    "    for idx in range(1, batch_target_length):\n",
    "        output, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "        y_idx = y[:, idx]\n",
    "        loss += F.cross_entropy(output, y_idx, ignore_index=0)\n",
    "        teacher_force = True if np.random.uniform() > teacher_forcing_ratio else False\n",
    "        if teacher_force:\n",
    "            decoder_input = y_idx.unsqueeze(1)\n",
    "        else:\n",
    "            decoder_input = output.argmax(dim=1).unsqueeze(1)\n",
    "    \n",
    "    # updating the gradient\n",
    "    loss.backward()\n",
    "    enc_optimizer.step()\n",
    "    dec_optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:29:54.837860Z",
     "start_time": "2020-06-16T03:29:52.160550Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(vocab2idx), 32, 64, len(df_train.code.unique())).to(device)\n",
    "decoder = Decoder(len(vocab2idx), 64, 64).to(device)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=3e-4)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:29:57.599749Z",
     "start_time": "2020-06-16T03:29:57.409203Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = tweetDataset(df_train, vocab2idx)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T03:52:01.481903Z",
     "start_time": "2020-06-16T03:49:09.705202Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dquan3/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c07f2c296464a91883d1c7d4612c1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss: 0.000 Time: 17.197\n",
      "Epoch: 2 Training Loss: 0.000 Time: 17.198\n",
      "Epoch: 3 Training Loss: 0.000 Time: 17.202\n",
      "Epoch: 4 Training Loss: 0.000 Time: 17.161\n",
      "Epoch: 5 Training Loss: 0.000 Time: 17.149\n",
      "Epoch: 6 Training Loss: 0.000 Time: 17.175\n",
      "Epoch: 7 Training Loss: 0.000 Time: 17.054\n",
      "Epoch: 8 Training Loss: 0.000 Time: 17.331\n",
      "Epoch: 9 Training Loss: 0.000 Time: 17.079\n",
      "Epoch: 10 Training Loss: 0.000 Time: 17.173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "1. double check the loss -> keep getting 0 loss.\n",
    "2. check the evaluation by translating the text back out.\n",
    "3. The dataset only has 27k rows so I originally did not split up the dataset. Create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
