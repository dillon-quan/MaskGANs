{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:31.398727Z",
     "start_time": "2020-06-17T20:06:31.393634Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:33.130670Z",
     "start_time": "2020-06-17T20:06:31.839579Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Torch Packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:33.775832Z",
     "start_time": "2020-06-17T20:06:33.132384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:33.979143Z",
     "start_time": "2020-06-17T20:06:33.777301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:33.994713Z",
     "start_time": "2020-06-17T20:06:33.980571Z"
    }
   },
   "outputs": [],
   "source": [
    "# index 314 has no text\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:34.088061Z",
     "start_time": "2020-06-17T20:06:33.996159Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_val, _, _ = train_test_split(df, \n",
    "                                          df['selected_text'], \n",
    "                                          test_size=.05, \n",
    "                                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:34.183005Z",
     "start_time": "2020-06-17T20:06:34.089936Z"
    }
   },
   "outputs": [],
   "source": [
    "# 26k samples in training to 1k samples in validation\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "* Lowercase - possible since the predicted sentiment text and the selected_text will be lowercase when computing metric.\n",
    "* punctuation - keep the punctuation given that the submission file states that need to be quoted and complete. \n",
    "* Numericalize - Turn each token into its corresponding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:35.636058Z",
     "start_time": "2020-06-17T20:06:35.631252Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    \"\"\"\n",
    "    This function will preprocess the input sentence sequence to avoid any further preprocessing\n",
    "    downstream.\n",
    "    \"\"\"\n",
    "    return sentence.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:36.357712Z",
     "start_time": "2020-06-17T20:06:36.051914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a5b022c1a94a6bbbec67116ed91414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428036db4e6046e1ae441a3eb871ee91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4219df33454e7fb596aa3578f0d30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153e3730ad75423fad667d6efcafafff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da00c2a11ff74e9486d6e3ec26ba193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3534.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lowercasing all the text and turning them into a list of tokens for text and selected text in the training set\n",
    "df_train['text'] = df_train['text'].progress_apply(preprocessing)\n",
    "df_val['text'] = df_val['text'].progress_apply(preprocessing)\n",
    "\n",
    "df_train['selected_text'] = df_train['selected_text'].progress_apply(preprocessing)\n",
    "df_val['selected_text'] = df_val['selected_text'].progress_apply(preprocessing)\n",
    "\n",
    "df_test['text'] = df_test['text'].progress_apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:38.161570Z",
     "start_time": "2020-06-17T20:06:38.142754Z"
    }
   },
   "outputs": [],
   "source": [
    "# making the sentiment to a variable\n",
    "df_train['sentiment'] = df_train['sentiment'].astype('category')\n",
    "df_train['code'] = df_train['sentiment'].cat.codes\n",
    "\n",
    "df_val['sentiment'] = df_val['sentiment'].astype('category')\n",
    "df_val['code'] = df_val['sentiment'].cat.codes\n",
    "\n",
    "df_test['sentiment'] = df_test['sentiment'].astype('category')\n",
    "df_test['code'] = df_test['sentiment'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:39.428632Z",
     "start_time": "2020-06-17T20:06:39.412368Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9937fa651b</td>\n",
       "      <td>[flew, home, from, london, to, ni, to, catch, ...</td>\n",
       "      <td>[flew, home, from, london, to, ni, to, catch, ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ae21c1ac38</td>\n",
       "      <td>[the, exception, for, a, short, dude:, larenz,...</td>\n",
       "      <td>[the, exception, for, a, short, dude:, larenz,...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>972c0874b2</td>\n",
       "      <td>[oh, no, matey,, did, you, get, ill?, it, woul...</td>\n",
       "      <td>[it, mea]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>babe8ab5bf</td>\n",
       "      <td>[i, am, so, sad..., how, come, pooch, hall, fr...</td>\n",
       "      <td>[i, am, so, sad...]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dc24138465</td>\n",
       "      <td>[http://twitpic.com/67iab, -, rounding, bases,...</td>\n",
       "      <td>[rounding, bases, -, she, was, fast, during, r...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  9937fa651b  [flew, home, from, london, to, ni, to, catch, ...   \n",
       "1  ae21c1ac38  [the, exception, for, a, short, dude:, larenz,...   \n",
       "2  972c0874b2  [oh, no, matey,, did, you, get, ill?, it, woul...   \n",
       "3  babe8ab5bf  [i, am, so, sad..., how, come, pooch, hall, fr...   \n",
       "4  dc24138465  [http://twitpic.com/67iab, -, rounding, bases,...   \n",
       "\n",
       "                                       selected_text sentiment  code  \n",
       "0  [flew, home, from, london, to, ni, to, catch, ...   neutral     1  \n",
       "1  [the, exception, for, a, short, dude:, larenz,...   neutral     1  \n",
       "2                                          [it, mea]  negative     0  \n",
       "3                                [i, am, so, sad...]  negative     0  \n",
       "4  [rounding, bases, -, she, was, fast, during, r...   neutral     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:55.485127Z",
     "start_time": "2020-06-17T20:06:55.479423Z"
    }
   },
   "outputs": [],
   "source": [
    "def unique_words(data):\n",
    "    \"\"\"\n",
    "    Find the number of unique words in the training set.\n",
    "    \"\"\"\n",
    "    words = set()\n",
    "    for text in data:\n",
    "        for word in text:\n",
    "            words.add(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:57.046937Z",
     "start_time": "2020-06-17T20:06:56.992840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43859"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unq_words = unique_words(df_train.text)\n",
    "len(unq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:57.386767Z",
     "start_time": "2020-06-17T20:06:57.380383Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(words):\n",
    "    vocab2idx, idx = {}, 4\n",
    "    vocab2idx['<pad>'] = 0\n",
    "    vocab2idx['<unk>'] = 1\n",
    "    vocab2idx['<sos>'] = 2\n",
    "    vocab2idx['<eos>'] = 3\n",
    "    \n",
    "    for word in words:\n",
    "        vocab2idx[word] = idx\n",
    "        idx += 1\n",
    "    return vocab2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:58.887279Z",
     "start_time": "2020-06-17T20:06:58.867677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43863"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2idx = create_vocabulary(unq_words)\n",
    "len(vocab2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:06:59.708311Z",
     "start_time": "2020-06-17T20:06:59.701596Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoding_with_no_padding(sentence, vocab2idx):\n",
    "    numericalize = [vocab2idx['<sos>']]\n",
    "    for token in sentence:\n",
    "        numericalize.append(vocab2idx.get(token, vocab2idx['<unk>']))\n",
    "    numericalize.append(vocab2idx['<eos>'])\n",
    "    return numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:07:04.732855Z",
     "start_time": "2020-06-17T20:07:04.719269Z"
    }
   },
   "outputs": [],
   "source": [
    "class tweetDataset(Dataset):\n",
    "    def __init__(self, data, vocab2idx):\n",
    "        self.X = [encoding_with_no_padding(x, vocab2idx) for x in data['text']]\n",
    "        self.y = [encoding_with_no_padding(y, vocab2idx) for y in data['selected_text']]\n",
    "        self.sentiment = data.code.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.X[idx]), torch.LongTensor(self.y[idx]), self.sentiment[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:07:06.494707Z",
     "start_time": "2020-06-17T20:07:06.313022Z"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "train_ds = tweetDataset(df_train, vocab2idx)\n",
    "valid_ds = tweetDataset(df_val, vocab2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:07:08.321367Z",
     "start_time": "2020-06-17T20:07:08.313487Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    (X, y, s) = zip(*batch)\n",
    "    x_len = [len(x) for x in X]\n",
    "    x_pad = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "    y_pad = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "    return x_pad, x_len, y_pad, torch.LongTensor(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:53:28.170686Z",
     "start_time": "2020-06-17T20:53:28.160330Z"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "batch_size = 3\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "x, lengths, y, s = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:34:41.363339Z",
     "start_time": "2020-06-17T20:34:41.350256Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, sentiment):\n",
    "        super().__init__()\n",
    "        self.vocabs = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.sentiment = nn.Embedding(sentiment, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(.5)\n",
    "        \n",
    "    def forward(self, x, lengths, sentiment):\n",
    "        x = self.dropout(self.vocabs(x))\n",
    "        x_pack = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, (hidden, cell) = self.lstm(x)\n",
    "        return torch.cat((torch.flatten(hidden.transpose(1,0), 1), self.sentiment(sentiment)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:54:14.503916Z",
     "start_time": "2020-06-17T20:54:14.493507Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.vocabs = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = self.vocabs(x)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        return self.linear(hidden[-1]), hidden, cell  #NOTE: hidden[-1] returns everything within that batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:30:56.326813Z",
     "start_time": "2020-06-17T20:30:56.320763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:52:23.188904Z",
     "start_time": "2020-06-17T20:52:23.063925Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(vocab2idx), 32, 64, 2, 3)\n",
    "decoder = Decoder(len(vocab2idx), 32, 288)  #NOTE: 288 is the dim after flatten and concatenating the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:46:29.107341Z",
     "start_time": "2020-06-17T20:46:29.084233Z"
    }
   },
   "outputs": [],
   "source": [
    "emb = nn.Embedding(len(vocab2idx), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:47:01.970684Z",
     "start_time": "2020-06-17T20:47:01.963853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 32])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = emb(x)\n",
    "e.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:56:49.652904Z",
     "start_time": "2020-06-17T20:56:49.646475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 288])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:56:57.985525Z",
     "start_time": "2020-06-17T20:56:57.980792Z"
    }
   },
   "outputs": [],
   "source": [
    "cell = torch.zeros(h.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T20:53:59.994286Z",
     "start_time": "2020-06-17T20:53:59.969620Z"
    }
   },
   "outputs": [],
   "source": [
    "#h = encoder(x, lengths, s)\n",
    "#h = h.unsqueeze(0)\n",
    "o, hid, s = decoder(x, (h, cell))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have added the bidirectional and 2 layers for the encoder. I have also changed the dimensions in the training batch. See how it will work later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:40:35.221761Z",
     "start_time": "2020-06-17T19:40:35.205979Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, valid_dl, \n",
    "                e_path, d_path, tf_ratio, epochs=10, save_val=False):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        start = time.time()\n",
    "        total_loss, total = 0, 0\n",
    "        val_loss, total_v = 0, 0\n",
    "        best_val = float('inf')\n",
    "        ### Training\n",
    "        for x, lengths, y, s in train_dl:\n",
    "            loss = train_batch(encoder, \n",
    "                               decoder, \n",
    "                               enc_optimizer, \n",
    "                               dec_optimizer, \n",
    "                               x.to(device), \n",
    "                               y.to(device), \n",
    "                               s.to(device), \n",
    "                               lengths, \n",
    "                               tf=True,\n",
    "                               tf_ratio=tf_ratio)\n",
    "            total_loss += loss*x.size(0)\n",
    "            total += x.size(0)\n",
    "        ### Validation\n",
    "        for x, lengths, y, s in valid_dl:\n",
    "            v_loss = train_batch(encoder, \n",
    "                                 decoder, \n",
    "                                 enc_optimizer, \n",
    "                                 dec_optimizer, \n",
    "                                 x.to(device), \n",
    "                                 y.to(device), \n",
    "                                 s.to(device), \n",
    "                                 lengths, \n",
    "                                 tf=False, \n",
    "                                 train=False)\n",
    "            val_loss += v_loss*x.size(0)\n",
    "            total_v += x.size(0)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch: {epoch+1} Train Loss: {total_loss/total:.3f} Val Loss: {val_loss/total_v:.3f} Time: {time.time()-start:.3f}\")\n",
    "        \n",
    "        if save_val:\n",
    "            if best_val > (val_loss/total_v):\n",
    "                save_model(encoder, decoder, e_path, d_path)\n",
    "                best_val = val_loss/total_v\n",
    "        else:\n",
    "            if best_val > (total_loss/total):\n",
    "                save_model(encoder, decoder, e_path, d_path)\n",
    "                best_val = total_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:40:35.692528Z",
     "start_time": "2020-06-17T19:40:35.678266Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_batch(encoder, decoder, enc_optimizer, dec_optimizer, x, y, s, lengths, tf,\n",
    "                train=True, tf_ratio=0.5):\n",
    "    if train:\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "    \n",
    "    # zero grad for both optimizers\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    # **ENCODER**\n",
    "    hidden = encoder(x, lengths, s)  # passing both the sequence and the sentiment\n",
    "    hidden = hidden.unsqueeze(0)\n",
    "    cell = torch.zeros(hidden.size())\n",
    "    \n",
    "    # **DECODER**\n",
    "    batch_target_length = y.size(1)  # NOTE: the length of the selected text\n",
    "    decoder_input = x[:, 0].unsqueeze(1)\n",
    "    \n",
    "    for idx in range(1, batch_target_length):\n",
    "        output, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "        y_idx = y[:, idx]\n",
    "        loss += F.cross_entropy(output, y_idx, ignore_index=0)\n",
    "        # if teacher forcing\n",
    "        if tf:\n",
    "            teacher_force = True if np.random.uniform() > tf_ratio else False\n",
    "            if teacher_force:\n",
    "                decoder_input = y_idx.unsqueeze(1)\n",
    "        else:\n",
    "            decoder_input = output.argmax(dim=1).unsqueeze(1)\n",
    "            \n",
    "    # updating the gradient\n",
    "    if train:\n",
    "        loss.backward()\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T18:31:40.340376Z",
     "start_time": "2020-06-17T18:31:40.332904Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(encoder, decoder, e_path, d_path):\n",
    "    torch.save(encoder.state_dict(), e_path)\n",
    "    torch.save(decoder.state_dict(), d_path)\n",
    "    \n",
    "def load_model(encoder, decoder, e_path, d_path):\n",
    "    encoder.load_state_dict(torch.load(e_path))\n",
    "    decoder.load_state_dict(torch.load(d_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T17:40:16.204087Z",
     "start_time": "2020-06-16T17:40:14.320481Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(vocab2idx), 32, 64, len(df_train.code.unique())).to(device)\n",
    "decoder = Decoder(len(vocab2idx), 64, 64).to(device)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=.001)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:40:53.393078Z",
     "start_time": "2020-06-17T19:40:53.222622Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = tweetDataset(df_train, vocab2idx)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T19:07:52.429580Z",
     "start_time": "2020-06-16T18:41:49.316406Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dquan3/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74799f5c50bb4249a1f0c15f9bb12347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 122.409 Val Loss: 209.773 Time: 15.686\n",
      "Epoch: 20 Train Loss: 108.441 Val Loss: 220.423 Time: 15.675\n",
      "Epoch: 30 Train Loss: 96.750 Val Loss: 228.607 Time: 15.626\n",
      "Epoch: 40 Train Loss: 88.033 Val Loss: 236.162 Time: 15.745\n",
      "Epoch: 50 Train Loss: 80.997 Val Loss: 243.644 Time: 15.641\n",
      "Epoch: 60 Train Loss: 75.322 Val Loss: 255.239 Time: 15.671\n",
      "Epoch: 70 Train Loss: 70.645 Val Loss: 259.033 Time: 15.653\n",
      "Epoch: 80 Train Loss: 66.571 Val Loss: 264.205 Time: 15.647\n",
      "Epoch: 90 Train Loss: 63.090 Val Loss: 273.947 Time: 15.420\n",
      "Epoch: 100 Train Loss: 60.302 Val Loss: 280.183 Time: 14.971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models/first_mod/'\n",
    "train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, valid_dl, \n",
    "            model_path + 'enc_lr_001_i32_h64_tf0.pth',\n",
    "            model_path + 'dec_lr_001_i64_h64_tf0.pth',\n",
    "            0,\n",
    "            100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:40:39.433802Z",
     "start_time": "2020-06-17T19:40:39.355272Z"
    }
   },
   "outputs": [],
   "source": [
    "# purposedly saving overfit model to test for sentence quality\n",
    "encoder = Encoder(len(vocab2idx), 32, 64, len(df_train.code.unique())).to(device)\n",
    "decoder = Decoder(len(vocab2idx), 64, 64).to(device)\n",
    "enc_optimizer = optim.Adam(encoder.parameters(), lr=.001)\n",
    "dec_optimizer = optim.Adam(decoder.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-17T19:40:56.008Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dquan3/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db94199ee1574b9d8dc47eeddf9a736e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 175.840 Val Loss: 185.926 Time: 15.709\n",
      "Epoch: 20 Train Loss: 154.785 Val Loss: 198.189 Time: 15.815\n",
      "Epoch: 30 Train Loss: 138.802 Val Loss: 206.112 Time: 15.824\n",
      "Epoch: 40 Train Loss: 124.085 Val Loss: 220.167 Time: 14.997\n",
      "Epoch: 50 Train Loss: 112.010 Val Loss: 224.912 Time: 15.812\n",
      "Epoch: 60 Train Loss: 102.239 Val Loss: 237.583 Time: 15.696\n",
      "Epoch: 70 Train Loss: 94.971 Val Loss: 242.505 Time: 15.019\n",
      "Epoch: 80 Train Loss: 89.204 Val Loss: 248.680 Time: 15.901\n",
      "Epoch: 90 Train Loss: 84.402 Val Loss: 258.046 Time: 15.697\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models/first_mod/'\n",
    "train_model(encoder, decoder, enc_optimizer, dec_optimizer, train_dl, valid_dl, \n",
    "            model_path + 'enc_lr_001_i32_h64_tf0_tr.pth',\n",
    "            model_path + 'dec_lr_001_i64_h64_tf0_tr.pth',\n",
    "            0,\n",
    "            200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T18:57:24.522804Z",
     "start_time": "2020-06-17T18:57:24.495889Z"
    }
   },
   "outputs": [],
   "source": [
    "idx2vocab = {v:k for k, v in list(vocab2idx.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:33:58.525839Z",
     "start_time": "2020-06-17T19:33:58.518654Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard(string1, string2):\n",
    "    a = set(string1.lower().split())\n",
    "    b = set(string2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:28:57.788718Z",
     "start_time": "2020-06-17T19:28:57.775628Z"
    }
   },
   "outputs": [],
   "source": [
    "def decoding(encoder, decoder, x, y, s, lengths):\n",
    "    decoded_words = []\n",
    "    total_jaccard, total = 0, 0\n",
    "    # **ENCODER**\n",
    "    hidden, cell = encoder(x, lengths, s)  # passing both the sequence and the sentiment\n",
    "    hidden = hidden.unsqueeze(0)\n",
    "    \n",
    "    # **DECODER**\n",
    "    batch_target_length = y.size(1)  # NOTE: the length of the selected text\n",
    "    decoder_input = x[:, 0].unsqueeze(1)\n",
    "    \n",
    "    for idx in range(1, batch_target_length):\n",
    "        output, hidden, cell = decoder(decoder_input, hidden, cell)\n",
    "        pred = output.argmax(dim=1)\n",
    "        decoded_words.append(pred)\n",
    "        decoder_input = pred.unsqueeze(1)\n",
    "    \n",
    "    decoded_words = torch.cat([tensor.unsqueeze(0) for tensor in decoded_words]).transpose(1,0)\n",
    "    \n",
    "    for i in range(decoded_words.size(0)):\n",
    "        xi = decoded_words[i].cpu().numpy()\n",
    "        yi = y[i].cpu().numpy()\n",
    "        x_sent = ' '.join([idx2vocab[idx] for idx in xi if idx > 3])\n",
    "        y_sent = ' '.join([idx2vocab[idx] for idx in yi if idx > 3])\n",
    "        total_jaccard += jaccard(x_sent, y_sent)\n",
    "        total += y.size(0)\n",
    "    return total_jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:31:50.018964Z",
     "start_time": "2020-06-17T19:31:50.010358Z"
    }
   },
   "outputs": [],
   "source": [
    "def jac_scoring(encoder, decoder, data_loader):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    jac_score, total = 0, 0\n",
    "    \n",
    "    for x, lengths, y, s in tqdm(data_loader):\n",
    "        jac_score += decoding(encoder, decoder, x.to(device), y.to(device), s.to(device), lengths)\n",
    "        total += x.size(0)\n",
    "    print(f\"Jaccard Similarity: {jac_score/total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:29:15.135611Z",
     "start_time": "2020-06-17T19:29:15.043014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model load\n",
    "encoder = Encoder(len(vocab2idx), 32, 64, len(df_train.code.unique())).to(device)\n",
    "decoder = Decoder(len(vocab2idx), 64, 64).to(device)\n",
    "load_model(encoder, decoder, 'models/first_mod/enc_lr_001_i32_h64_tf0.pth', 'models/first_mod/dec_lr_001_i64_h64_tf0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T19:34:56.677680Z",
     "start_time": "2020-06-17T19:34:03.870104Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dquan3/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d93610565af46adb0da93afea7a55a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8702.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard Similarity: 0.000\n"
     ]
    }
   ],
   "source": [
    "jac_scoring(encoder, decoder, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
